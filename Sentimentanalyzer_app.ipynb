{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MXABdQBZnPQf"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade streamlit\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJC6hjfRnX2N",
        "outputId": "c98ae131-6199-4ad2-c23e-11d4c8eb7aa9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.26.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata<7,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.8.0)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.23.5)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n",
            "Requirement already satisfied: pillow<10,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: pympler<2,>=0.9 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.18 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.5.2)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.7.1)\n",
            "Requirement already satisfied: tzlocal<5,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.3.1)\n",
            "Requirement already satisfied: validators<1,>=0.2 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.21.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.32)\n",
            "Requirement already satisfied: pydeck<1,>=0.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.8.0)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.2)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.0.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=1.4->streamlit) (3.16.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.18->streamlit) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.18->streamlit) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.18->streamlit) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.18->streamlit) (2023.7.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Requirement already satisfied: pytz-deprecation-shim in /usr/local/lib/python3.10/dist-packages (from tzlocal<5,>=1.1->streamlit) (0.1.0.post0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.9.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.10/dist-packages (from pytz-deprecation-shim->tzlocal<5,>=1.1->streamlit) (2023.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%writefile app.py\n",
        "\n",
        "import webbrowser\n",
        "\n",
        "\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import re\n",
        "import contractions\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import webbrowser\n",
        "\n",
        "# Initialize the SentimentIntensityAnalyzer\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Define the Lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def cleaner(text):\n",
        "    \"\"\"\n",
        "    Clean and preprocess a given text using various steps.\n",
        "\n",
        "    This function applies a series of cleaning operations to the input text, including replacing contractions,\n",
        "    removing hashtags and Twitter handles, eliminating URLs, converting to lowercase, and lemmatizing words.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text to be cleaned.\n",
        "\n",
        "    Returns:\n",
        "        str: The cleaned and preprocessed text.\n",
        "    \"\"\"\n",
        "    new_text = re.sub(r\"'s\\b\", \" is\", text)\n",
        "    new_text = re.sub(\"#\", \"\", new_text)\n",
        "    new_text = re.sub(\"@[A-Za-z0-9]+\", \"\", new_text)\n",
        "    new_text = re.sub(r\"http\\S+\", \"\", new_text)\n",
        "    new_text = contractions.fix(new_text)\n",
        "    new_text = re.sub(r\"[^a-zA-Z]\", \" \", new_text)\n",
        "    new_text = new_text.lower().strip()\n",
        "\n",
        "    cleaned_text = ''\n",
        "    for token in new_text.split():\n",
        "        cleaned_text = cleaned_text + lemmatizer.lemmatize(token) + ' '\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Preprocess a given text for further analysis.\n",
        "\n",
        "    This function takes the input text, applies the 'cleaner' function, tokenizes the cleaned text,\n",
        "    removes punctuation and stopwords, and then reconstructs the preprocessed text.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text to be preprocessed.\n",
        "\n",
        "    Returns:\n",
        "        str: The preprocessed text ready for analysis.\n",
        "    \"\"\"\n",
        "    if isinstance(text, str):\n",
        "        # Apply the 'cleaner' function\n",
        "        cleaned_text = cleaner(text)\n",
        "\n",
        "        # Tokenization\n",
        "        tokens = word_tokenize(cleaned_text)\n",
        "\n",
        "        # Remove punctuation\n",
        "        tokens = [token for token in tokens if token not in string.punctuation]\n",
        "\n",
        "        # Remove stopwords\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "        # Reconstruct preprocessed text\n",
        "        preprocessed_text = ' '.join(tokens)\n",
        "        return preprocessed_text\n",
        "    else:\n",
        "        # If the input is not a string, return an empty string\n",
        "        return ''\n",
        "\n",
        "# Streamlit app header\n",
        "st.header('Sentiment Analysis')\n",
        "\n",
        "# Text input for sentiment analysis\n",
        "text_input = st.text_input('Enter text for sentiment analysis:')\n",
        "\n",
        "if text_input:\n",
        "    # Calculate sentiment scores\n",
        "    sentiment_scores = sid.polarity_scores(text_input)\n",
        "    polarity = sentiment_scores['compound']\n",
        "\n",
        "    # Classify sentiment\n",
        "    if polarity > 0.6:\n",
        "        sentiment = 'Positive'\n",
        "        sentiment_text = 'This text is positive!'\n",
        "    elif polarity < 0.1:\n",
        "        sentiment = 'Negative'\n",
        "        sentiment_text = 'This text is negative.'\n",
        "    else:\n",
        "        sentiment = 'Neutral'\n",
        "        sentiment_text = 'This text is neutral.'\n",
        "\n",
        "    # Display sentiment scores, classification, and associated text\n",
        "    st.write('Sentiment Scores:', sentiment_scores)\n",
        "    st.write('Sentiment:', sentiment)\n",
        "    st.write('Sentiment Text:', sentiment_text)\n",
        "\n",
        "# Text input for text cleaning\n",
        "clean_input = st.text_input('Enter text to clean:')\n",
        "\n",
        "if clean_input:\n",
        "    # Clean and preprocess text\n",
        "    cleaned_text = cleaner(clean_input)\n",
        "    preprocessed_text = preprocess_text(cleaned_text)\n",
        "\n",
        "    # Display cleaned and preprocessed text\n",
        "    st.write('Cleaned Text:', cleaned_text)\n",
        "    st.write('Preprocessed Text:', preprocessed_text)\n",
        "\n",
        "with st.expander('Analyze CSV'):\n",
        "    upl = st.file_uploader('Upload file')\n",
        "\n",
        "    if upl:\n",
        "        df = pd.read_csv(upl)\n",
        "\n",
        "        # ... (your score and analyze functions)\n",
        "\n",
        "        df['score'] = df['reviews.text'].apply(score)\n",
        "        df['analysis'] = df['score'].apply(analyze)\n",
        "        st.write(df.head(10))\n",
        "\n",
        "        @st.cache\n",
        "        def convert_df(df):\n",
        "            return df.to_csv(index=False).encode('utf-8')\n",
        "\n",
        "        csv = convert_df(df)\n",
        "\n",
        "        st.download_button(\n",
        "            label=\"Download data as CSV\",\n",
        "            data=csv,\n",
        "            file_name='sentiment.csv',\n",
        "            mime='text/csv'\n",
        "        )\n",
        "\n",
        "# Streamlit app header\n",
        "st.header('Open tableau')\n",
        "\n",
        "# URL to open\n",
        "link_url = \"https://public.tableau.com/views/updatedproject_16930187945980/Dashboard1?:language=en-US&publish=yes&:display_count=n&:origin=viz_share_link\"\n",
        "\n",
        "\n",
        "st.markdown(f'[Click here to open]({link_url})')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69cLi3AKnaGT",
        "outputId": "751caca9-2e3d-4cd3-ff49-003a8e825e07"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IuRxwX1wnkI3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KgaibwGDnpPj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}